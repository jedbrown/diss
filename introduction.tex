A large amount of scientific effort worldwide is focused on understanding and predicting the advance and consequences of climate change, due to its potentially disastrous affects on human society.
Increasingly, the results of numerical models are being used to influence decisions regarding energy policy, water rights, property values, geoengineering projects, and many more.
Thus climate science, once an academic pursuit, is transforming into an engineering project of the grandest scale, the success of which will affect the entire planet.
However, in stark contrast to other engineering disciplines, the ``product development'' latency for climate is a human lifetime or more, observations are difficult to obtain, and experimental perturbation is nearly impossible.
This contributes to an environment in which the people creating and using numerical models never have direct feedback to assess the quality of the numerical results.
Additionally, there is no direct financial incentive to produce quality results.
Indeed, the quality of the results may never be known within the lifetime of the scientist who creates them.

The situation is very different in the industrial setting.
If a computer program is used to design a plane that malfunctions, a bridge or dam that collapses, an engine with poor efficiency, or a reservoir engineering plan that results in poor recovery, there is process of accountability.
Poor numerical results have direct financial and/or political consequences for the company or organization responsible.
In such fields, it was learned early on that the process of verification and validation~\citep{roache1998verification,babuska2004vav} is of paramount importance.
Numerical and computational issues cannot be merely an afterthought, and short cuts generally lead to incorrect results and poor understanding of complex phenomena.

This philosophy was summarized well in the 1986 Editorial Policy Statement on the Control of Numerical Accuracy for the Journal of Fluids Engineering~\citep{roache1986editorial}.
This statement was unequivocal that the time for less rigorous analysis and testing of methods had long passed, and announced that the jouarnal ``will not accept for publication any paper reporting the numerical solution of a fluids engineering problem that fails to address the task of systematic truncation error testing and accuracy estimation.''
In particular, ``a single calculation in a fixed grid will not be acceptable'' and ``the editors will not consider a reasonable agreement with experimental data to be sufficient proof of accuracy, especially if any adjustable parameters are involved.''
This policy was strengthened and extended in 1993 to its current form~\citep{jfe2004numaccuracy} which defines a list of ten criteria that must be used to assess the accuracy, robustness, efficiency, and proper documentation of a numerical method in order for it to be considered by the journal.
Many other engineering journals have since adopted similar editorial policies.
It is clear from the list, and has been confirmed by numerous colleagues in each discipline of climate modeling, that there does not exist a single climate component in any discipline that comes close to satisfying these publication criteria.
This must change if the results of numerical models are to be taken seriously in the future.

Unfortunately, careful study of spatial discretization and grid convergence is not sufficient to enable the next generation of scientific inquiry for multiphysics systems such as climate or even ice dynamics in isolation.
Time discretization and implicit solver performance must also be addressed.
As argued by a recent Department of Energy panel~\citep{simon2007modeling}, current models invariably rely on ``first-order accurate operator-splitting, semi-implicit and explicit time integration methods, and decoupled nonlinear solution strategies.
Such methods have not provided the stability properties needed to perform accurate simulations over the dynamical time-scales of interest.
Moreover, in most cases, numerical errors and means for controlling such errors are understood heuristically at best.''
This and a related report~\citep{washington2009scientific} prioritize further research in fast, robust linear and nonlinear solvers because these ``will directly determine the scope of feasible problems to be solved'' as, inevitably, implicit formulations and advanced analysis techniques such as optimization, uncertainty quantification, and stability and sensitivity analysis assume a central role.

Ice dynamics was identified by the fourth assessment report of the IPCC~\citep{lemk2007ar4wg1} as a crucial source of uncertainty in sea level rise estimates, with no existing models capable of simulating the physical processes responsible for the large uncertainty.
The underlying source of this uncertainty is a dynamical instability identified by \citet{weertman1974sji} and made rigorous by \citet{schoof2007isg}.
The problem of grounding line stability in locations such as Jakobshavn Isbr{\ae} is fundamentally three dimensional, constant factors are important, and the overall stability is determined by multi-scale behavior such as heat flux from the ocean through thin boundary layers and small bed features that can stabilize an unstable state.
The ``full'' grounding line stability problem is on the frontier of computational science in many ways.
It involves coupling physical processes in multiple domains interacting on multiple time scales through boundary layer processes, with material and geometric anisotropy, strong nonlinearity and heterogeneity, mixed characteristic PDEs, four varieties of interacting contact problems, and uncertainty in the geometry, coefficients, and constitutive models.

Advances in geoscience simulations will come from the synergy of
\begin{itemize}
\item more accurate physical models,
\item more sophisticated mathematical algorithms, and
\item more efficient implementations of these models and algorithms that take into account recent advances in computer hardware.
\end{itemize}
This synergy can only occur within a comprehensive well-thought-out software infrastructure that reflects all three facets of simulation.
This thesis contains my work on each of these topics and their synthesis.
It attempts to bring a more rigorous understanding of numerical and computational issues in ice flow modeling, with a focus on robust, extensible methods that scale to large problem sizes with efficient use of current and future hardware.
An overarching theme is the development of extensible software that can be used to solve increasingly complex problems with minimal development time, while using the best possible methods.
Much of this software has been added to the {\PETSc}~\citep{petsc-user-ref} library\footnote{%
The Portable Extensible Toolkit for Scientific computing ({\PETSc}) is an open source parallel nonlinear solvers package with support for many related tasks in scientific computing.
It has thousands of users in academia and industry, with uses ranging from development of new iterative and preconditioning methods to computational physics and engineering problems in many fields, and forms the solver infrastructure for many discretization libraries as well as commercial software.
I have been an active developer since 2008 and any developments that I felt belonged at {\PETSc}'s level of abstraction have been added to the library.}
and is in production use by many external groups.
Components which are not part of {\PETSc} are available under a BSD-style open source license.

\section{Summary of contributions}

\chapref{chap:dohp} presents new perspective on high-order methods for finite element analysis.
This formulation is well-suited to advances in linear and nonlinear solvers and offers dramatically better utilization of modern hardware than conventional methods.
\Dohp, a new general purpose library based on this method is presented, and the performance is shown to be several times faster than other widely used finite element libraries.
Through new software interfaces, this performance is achieved while retaining more run-time flexibility in terms of element and preconditioning choice, and drastically better performance as the order of the element increases.
The library also retains more geometric information than existing open source libraries, permitting more natural coupling to CAD and geometric models, as well as the implicit solution of equations in which the domain is part of the solution.

In \chapref{chap:tme-ice}, a new Newton-Krylov-Multigrid solver for the hydrostatic equations of ice sheet flow is presented.
The high cost of solving the hydrostatic equations using conventional methods has been the principle impediment to their use in large-scale ice sheet models, causing existing models to fall back to simpler momentum balance models.
In addition to poor algorithms, the community has also suffered from lack of quality parallel implementations, thus further limiting the scope of problems that could be solved.
The new solver demonstrates textbook multigrid efficiency on a variety of demanding problems, offering several orders of magnitude speedup for problem sizes of interest, and nearly perfect strong and weak scalability on parallel hardware.
The code is available as a tutorial in {\PETSc}.

\chapref{chap:software} discusses several of the software components that were implemented to facilitate efficient solvers for multiphysics problems, high throughput, flexible and performant finite element methods for coupled problems, and designing code for easy verification.
A new algebraic interface for multiphysics coupling is introduced.
Robust coupling of multiple interacting physical processes is a challenging problem in which many commonly used methods are fundamentally inadequate.
The best methods are highly problem dependent, change as the number of coupled processes grows, and are a highly active area of research.
A crucial limitation of earlier software was that trying different methods generally involved a great deal of error-prone software development by the user.
This poor software support made it difficult to test the quality and performance of different methods, thus locking projects in to methods that may eventually prove to be ill-suited to the problems of interest.
The new algebraic interface allows an arbitrary number of physical processes to be coupled using a wide range of methods that can be selected and composed at run-time.
It permits straightforward reuse of single physics modules with no code modification, thus offering better support for model verification and extensibility.
The interface offers higher performance and a great deal more flexibility in choice of methods than previous software.
This software, along with implicit time integrators for differential algebraic equations and optimal explicit strong stability preserving integrators for hyperbolic systems, has been added to {\PETSc} and is in production use by several external groups.

Improvements in throughput for sparse matrix kernels and unassembled finite element discretizations are presented.
Common methods for solving partial differential equations exhibit very low utilization of modern hardware, often less than 5 percent, due to their overwhelming dependence on memory bandwidth.
Part of this under-utilization was due to implementation issues with sparse matrix kernels preventing good reuse of high-level caches.
This was rectified within this work by improving \PETSc's sparse matrix kernels by 20 to 30 percent, and performance is now close to the theoretical limit of the hardware.
The more fundamental limitation of memory bandwidth cannot be overcome by implementation optimization; it requires changing the underlying algorithm.
In the context of the finite element library \Dohp, this can be achieved by eschewing assembled sparse matrices in favor of a matrix-free representation that has higher arithmetic intensity and uses much less memory for everything beyond lowest order elements.
This transformation permits an order of magnitude improvement in hardware utilization and is transparently available to the user in the {\Dohp} library.
Improved support for such unassembled representations was integrated into the multi-physics coupling interface.

\chapref{chap:discretization} investigates several relatively unique discretization requirements for ice flow problems.
Robustness and accuracy requirements for ice flow problems place many constraints on the discretization and treatment of boundary conditions.
Many of these technical requirements are relatively unique to ice flow problems, but are undocumented in the glaciology literature, thus hampering current efforts for robust simulation.
These technical issues are investigated in \chapref{chap:discretization} and conclusions are drawn, with practical consequences to the present work and future development of methods for ice flow.

Finally, \chapref{chap:jakobshavn} applies the tools developed earlier to a conservative formulation for polythermal ice flow and to the Jakobshavn Isbr{\ae} ice stream.
Current formulations for polythermal ice do not account for density variation caused by melt fraction and thus commit a conservation error of first order in the melt fraction.
A new continuum formulation that exactly conserves mass, momentum, and energy independent of the melt fraction is presented.
A high order finite element discretization for this system is proposed and numerical accuracy is addressed using manufactured solutions.
This formulation treats all terms, including energy transport, implicitly in time, which allows the direct application of Newton-Krylov methods to compute the steady state.
Steady state solutions are useful for parameter inversion, ``spin up'', and stability analysis.
They are conventionally computed using direct time integration with a time step size constrained by the CFL stability criterion.
With this constraint, they require a mesh-dependent number of time steps, typically very large, to reach steady state.
The Newton-Krylov method converges in a small, mesh-independent number of iterations.
This steady-state solver is applied to a section of the ice stream channel at Jakobshavn Isbr{\ae}.
Setting up a model of an outlet glacier using realistic geometry and boundary conditions is a time-consuming task.
This is especially true if a geometric model is needed to define slip conditions, or if the mesh needs to conform to the grounding line.
Visualization is also complicated by the need to georeference model results.
These difficulties have been partially mitigated by having the analysis code work with georeferenced input in any format and any projection, and produce georeferenced output.
